{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7+8rTcmDpGDDpYB5v0XKJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haimfeld/fun_projects/blob/CuisineMatcher/llms/food_decision_helper/CuisineMatcher_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtRC_K6QbiiM",
        "outputId": "4f7d86d6-8053-4c4a-ae3e-37696df41d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "×¡×¤×¨ ×œ×™ ××™×–×” ××•×›×œ ×‘× ×œ×š ×•××” ×”××–×•×¨ (×¢×‘×¨×™×ª ××• ×× ×’×œ×™×ª): ×”×•×“×™\n",
            "ğŸ½ï¸ ×”× ×” ××¡×¢×“×•×ª ×‘×©×‘×™×œ×š:\n",
            "- ××•× ××¨ (indian)\n",
            "  ××™×§×•×: https://www.google.com/maps/search/?api=1&query=32.0612686,34.7724007\n",
            "- Munnar (indian)\n",
            "  ××™×§×•×: https://www.google.com/maps/search/?api=1&query=32.061255,34.772392\n",
            "- Davi (None)\n",
            "  ××™×§×•×: https://www.google.com/maps/search/?api=1&query=32.0581679,34.7660056\n",
            "- ×§×•×¤×™ ×‘×¨ (italian)\n",
            "  ××™×§×•×: https://www.google.com/maps/search/?api=1&query=32.0619564,34.783623\n"
          ]
        }
      ],
      "source": [
        "# !pip install transformers sentence-transformers faiss-cpu\n",
        "\n",
        "import requests\n",
        "import random\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# ===== CONFIG =====\n",
        "LAT_LON_DEFAULT = (32.062882, 34.769206)  # Center of Tel Aviv\n",
        "RADIUS = 1500  # meters\n",
        "\n",
        "# ===== STEP 1: OSM Query =====\n",
        "def get_restaurants(lat, lon, radius=RADIUS):\n",
        "    query = f\"\"\"\n",
        "    [out:json][timeout:60];\n",
        "    node[\"amenity\"=\"restaurant\"](around:{radius},{lat},{lon});\n",
        "    out;\n",
        "    \"\"\"\n",
        "    try:\n",
        "        r = requests.get(\"https://overpass-api.de/api/interpreter\", params={\"data\": query}, timeout=30)\n",
        "        data = r.json()\n",
        "    except:\n",
        "        print(\"Error fetching data from OSM\")\n",
        "        return []\n",
        "    restaurants = []\n",
        "    for n in data.get(\"elements\", []):\n",
        "        name = n.get(\"tags\", {}).get(\"name\")\n",
        "        cuisine = n.get(\"tags\", {}).get(\"cuisine\")\n",
        "        if name:\n",
        "            restaurants.append({\n",
        "                \"name\": name,\n",
        "                \"cuisine\": cuisine,\n",
        "                \"lat\": n[\"lat\"],\n",
        "                \"lon\": n[\"lon\"]\n",
        "            })\n",
        "    return restaurants\n",
        "\n",
        "# ===== STEP 2: Simple AI Matching =====\n",
        "# Use a small multilingual embedding model to match cuisine keywords\n",
        "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "def match_restaurants(user_input, restaurants):\n",
        "    if not restaurants:\n",
        "        return []\n",
        "\n",
        "    # Build embeddings for restaurant names + cuisine\n",
        "    texts = [f\"{r['name']} {r.get('cuisine','')}\" for r in restaurants]\n",
        "    embeddings = model.encode(texts, convert_to_tensor=True)\n",
        "\n",
        "    # Embed user input\n",
        "    user_emb = model.encode(user_input, convert_to_tensor=True)\n",
        "\n",
        "    # Compute similarity\n",
        "    similarities = util.cos_sim(user_emb, embeddings)[0]\n",
        "    scores = similarities.cpu().tolist()\n",
        "\n",
        "    # Pick top 3 matches\n",
        "    top_idx = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:4]\n",
        "    top_restaurants = [restaurants[i] for i in top_idx]\n",
        "    return top_restaurants\n",
        "\n",
        "# ===== STEP 3: AI Agent =====\n",
        "def ai_food_agent(user_input):\n",
        "    lat, lon = LAT_LON_DEFAULT\n",
        "    restaurants = get_restaurants(lat, lon)\n",
        "    if not restaurants:\n",
        "        print(\"×œ× × ××¦××• ××¡×¢×“×•×ª ×‘××–×•×¨ ×”×§×¨×•×‘.\")\n",
        "        return\n",
        "\n",
        "    top_choices = match_restaurants(user_input, restaurants)\n",
        "\n",
        "    print(\"ğŸ½ï¸ ×”× ×” ××¡×¢×“×•×ª ×‘×©×‘×™×œ×š:\")\n",
        "    for r in top_choices:\n",
        "        print(f\"- {r['name']} ({r.get('cuisine','×œ× ×™×“×•×¢')})\")\n",
        "        print(f\"  ××™×§×•×: https://www.google.com/maps/search/?api=1&query={r['lat']},{r['lon']}\")\n",
        "\n",
        "# ===== RUN =====\n",
        "if __name__ == \"__main__\":\n",
        "    user_input = input(\"×¡×¤×¨ ×œ×™ ××™×–×” ××•×›×œ ×‘× ×œ×š (×¢×‘×¨×™×ª ××• ×× ×’×œ×™×ª): \")\n",
        "    ai_food_agent(user_input)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkHWdh17irXM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}